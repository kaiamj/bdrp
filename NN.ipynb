{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kaiamj/bdrp/blob/main/NN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "pNFafoLefI5L",
        "outputId": "eb48a9f9-7b27-4616-d4ac-52a896892cc6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting git+https://github.com/instadeepai/jumanji.git\n",
            "  Cloning https://github.com/instadeepai/jumanji.git to /tmp/pip-req-build-c89_c19d\n",
            "  Running command git clone -q https://github.com/instadeepai/jumanji.git /tmp/pip-req-build-c89_c19d\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting chex>=0.1.3\n",
            "  Downloading chex-0.1.5-py3-none-any.whl (85 kB)\n",
            "\u001b[K     |████████████████████████████████| 85 kB 3.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: gym>=0.22.0 in /usr/local/lib/python3.7/dist-packages (from jumanji==0.1.3) (0.25.2)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.7/dist-packages (from jumanji==0.1.3) (1.21.6)\n",
            "Requirement already satisfied: jax>=0.2.26 in /usr/local/lib/python3.7/dist-packages (from jumanji==0.1.3) (0.3.25)\n",
            "Requirement already satisfied: jaxlib>=0.1.74 in /usr/local/lib/python3.7/dist-packages (from jumanji==0.1.3) (0.3.25+cuda11.cudnn805)\n",
            "Collecting Pillow>=9.0.0\n",
            "  Downloading Pillow-9.3.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.2 MB 66.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from jumanji==0.1.3) (4.1.1)\n",
            "Collecting pygame>=2.0.0\n",
            "  Downloading pygame-2.1.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (21.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 21.8 MB 1.2 MB/s \n",
            "\u001b[?25hCollecting matplotlib>=3.3.4\n",
            "  Downloading matplotlib-3.5.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (11.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 11.2 MB 47.5 MB/s \n",
            "\u001b[?25hCollecting brax>=0.0.10\n",
            "  Downloading brax-0.0.15-py3-none-any.whl (372 kB)\n",
            "\u001b[K     |████████████████████████████████| 372 kB 68.6 MB/s \n",
            "\u001b[?25hCollecting dm-env>=1.5\n",
            "  Downloading dm_env-1.5-py3-none-any.whl (26 kB)\n",
            "Collecting dataclasses\n",
            "  Downloading dataclasses-0.6-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.7/dist-packages (from brax>=0.0.10->jumanji==0.1.3) (1.3.0)\n",
            "Requirement already satisfied: grpcio in /usr/local/lib/python3.7/dist-packages (from brax>=0.0.10->jumanji==0.1.3) (1.50.0)\n",
            "Collecting tensorboardX\n",
            "  Downloading tensorboardX-2.5.1-py2.py3-none-any.whl (125 kB)\n",
            "\u001b[K     |████████████████████████████████| 125 kB 74.0 MB/s \n",
            "\u001b[?25hCollecting pytinyrenderer\n",
            "  Downloading pytinyrenderer-0.0.13-cp37-cp37m-manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 71.3 MB/s \n",
            "\u001b[?25hCollecting trimesh\n",
            "  Downloading trimesh-3.16.4-py3-none-any.whl (663 kB)\n",
            "\u001b[K     |████████████████████████████████| 663 kB 61.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=6.0 in /usr/local/lib/python3.7/dist-packages (from brax>=0.0.10->jumanji==0.1.3) (6.0)\n",
            "Collecting flax\n",
            "  Downloading flax-0.6.2-py3-none-any.whl (189 kB)\n",
            "\u001b[K     |████████████████████████████████| 189 kB 78.7 MB/s \n",
            "\u001b[?25hCollecting optax\n",
            "  Downloading optax-0.1.4-py3-none-any.whl (154 kB)\n",
            "\u001b[K     |████████████████████████████████| 154 kB 76.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: toolz>=0.9.0 in /usr/local/lib/python3.7/dist-packages (from chex>=0.1.3->jumanji==0.1.3) (0.12.0)\n",
            "Requirement already satisfied: dm-tree>=0.1.5 in /usr/local/lib/python3.7/dist-packages (from chex>=0.1.3->jumanji==0.1.3) (0.1.7)\n",
            "Requirement already satisfied: gym-notices>=0.0.4 in /usr/local/lib/python3.7/dist-packages (from gym>=0.22.0->jumanji==0.1.3) (0.0.8)\n",
            "Requirement already satisfied: importlib-metadata>=4.8.0 in /usr/local/lib/python3.7/dist-packages (from gym>=0.22.0->jumanji==0.1.3) (4.13.0)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from gym>=0.22.0->jumanji==0.1.3) (1.5.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.8.0->gym>=0.22.0->jumanji==0.1.3) (3.10.0)\n",
            "Requirement already satisfied: opt-einsum in /usr/local/lib/python3.7/dist-packages (from jax>=0.2.26->jumanji==0.1.3) (3.3.0)\n",
            "Requirement already satisfied: scipy>=1.5 in /usr/local/lib/python3.7/dist-packages (from jax>=0.2.26->jumanji==0.1.3) (1.7.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.3.4->jumanji==0.1.3) (1.4.4)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.3.4->jumanji==0.1.3) (0.11.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.3.4->jumanji==0.1.3) (21.3)\n",
            "Requirement already satisfied: pyparsing>=2.2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.3.4->jumanji==0.1.3) (3.0.9)\n",
            "Collecting fonttools>=4.22.0\n",
            "  Downloading fonttools-4.38.0-py3-none-any.whl (965 kB)\n",
            "\u001b[K     |████████████████████████████████| 965 kB 47.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.3.4->jumanji==0.1.3) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.4->jumanji==0.1.3) (1.15.0)\n",
            "Requirement already satisfied: msgpack in /usr/local/lib/python3.7/dist-packages (from flax->brax>=0.0.10->jumanji==0.1.3) (1.0.4)\n",
            "Collecting tensorstore\n",
            "  Downloading tensorstore-0.1.28-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 8.3 MB 66.2 MB/s \n",
            "\u001b[?25hCollecting rich>=11.1\n",
            "  Downloading rich-12.6.0-py3-none-any.whl (237 kB)\n",
            "\u001b[K     |████████████████████████████████| 237 kB 63.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pygments<3.0.0,>=2.6.0 in /usr/local/lib/python3.7/dist-packages (from rich>=11.1->flax->brax>=0.0.10->jumanji==0.1.3) (2.6.1)\n",
            "Collecting commonmark<0.10.0,>=0.9.0\n",
            "  Downloading commonmark-0.9.1-py2.py3-none-any.whl (51 kB)\n",
            "\u001b[K     |████████████████████████████████| 51 kB 8.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf<=3.20.1,>=3.8.0 in /usr/local/lib/python3.7/dist-packages (from tensorboardX->brax>=0.0.10->jumanji==0.1.3) (3.19.6)\n",
            "Building wheels for collected packages: jumanji\n",
            "  Building wheel for jumanji (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for jumanji: filename=jumanji-0.1.3-py3-none-any.whl size=166478 sha256=9663c38686036ecaa714973652bb7b512e77e0ac8fb0c6794d4072d7be37e747\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-mlt08xg4/wheels/50/fe/b5/c8538a7aaa5be9520dfc72aa166dc9d16e4a57ffc9c4abdea6\n",
            "Successfully built jumanji\n",
            "Installing collected packages: Pillow, fonttools, commonmark, chex, tensorstore, rich, optax, matplotlib, trimesh, tensorboardX, pytinyrenderer, flax, dm-env, dataclasses, pygame, brax, jumanji\n",
            "  Attempting uninstall: Pillow\n",
            "    Found existing installation: Pillow 7.1.2\n",
            "    Uninstalling Pillow-7.1.2:\n",
            "      Successfully uninstalled Pillow-7.1.2\n",
            "  Attempting uninstall: matplotlib\n",
            "    Found existing installation: matplotlib 3.2.2\n",
            "    Uninstalling matplotlib-3.2.2:\n",
            "      Successfully uninstalled matplotlib-3.2.2\n",
            "Successfully installed Pillow-9.3.0 brax-0.0.15 chex-0.1.5 commonmark-0.9.1 dataclasses-0.6 dm-env-1.5 flax-0.6.2 fonttools-4.38.0 jumanji-0.1.3 matplotlib-3.5.3 optax-0.1.4 pygame-2.1.2 pytinyrenderer-0.0.13 rich-12.6.0 tensorboardX-2.5.1 tensorstore-0.1.28 trimesh-3.16.4\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "PIL",
                  "matplotlib",
                  "mpl_toolkits"
                ]
              }
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "!pip install git+https://github.com/instadeepai/jumanji.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QvhuPtb0h_km",
        "outputId": "616b7068-6d20-455b-bb55-2dd928defddc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/jax/_src/numpy/lax_numpy.py:173: UserWarning: Explicitly requested dtype float64 requested in asarray is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
            "  return asarray(x, dtype=self.dtype)\n",
            "/usr/local/lib/python3.7/dist-packages/jax/_src/ops/scatter.py:90: FutureWarning: scatter inputs have incompatible types: cannot safely cast value from dtype=float32 to dtype=int32. In future JAX releases this will result in an error.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/jax/_src/ops/scatter.py:90: FutureWarning: scatter inputs have incompatible types: cannot safely cast value from dtype=float32 to dtype=int32. In future JAX releases this will result in an error.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/jax/_src/ops/scatter.py:90: FutureWarning: scatter inputs have incompatible types: cannot safely cast value from dtype=float32 to dtype=int32. In future JAX releases this will result in an error.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/jax/_src/ops/scatter.py:90: FutureWarning: scatter inputs have incompatible types: cannot safely cast value from dtype=float32 to dtype=int32. In future JAX releases this will result in an error.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/jax/_src/ops/scatter.py:90: FutureWarning: scatter inputs have incompatible types: cannot safely cast value from dtype=float32 to dtype=int32. In future JAX releases this will result in an error.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/jax/_src/ops/scatter.py:90: FutureWarning: scatter inputs have incompatible types: cannot safely cast value from dtype=float32 to dtype=int32. In future JAX releases this will result in an error.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/jax/_src/numpy/lax_numpy.py:173: UserWarning: Explicitly requested dtype float64 requested in asarray is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
            "  return asarray(x, dtype=self.dtype)\n",
            "/usr/local/lib/python3.7/dist-packages/jax/_src/numpy/lax_numpy.py:173: UserWarning: Explicitly requested dtype float64 requested in asarray is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
            "  return asarray(x, dtype=self.dtype)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.0\n"
          ]
        }
      ],
      "source": [
        "import jax\n",
        "import jax.numpy as jnp\n",
        "import jumanji\n",
        "from jumanji.wrappers import AutoResetWrapper\n",
        "key = jax.random.PRNGKey(0)\n",
        "env = jumanji.make(\"BinPack-toy-v0\")\n",
        "state, timestep = env.reset(0)\n",
        "# Randomly choose ems_id and item_id using the action mask\n",
        "\n",
        "num_ems, num_items = env.action_spec().num_values\n",
        "ems_item_id = jax.random.choice(\n",
        "    key=key,\n",
        "    a=num_ems * num_items,\n",
        "    p=timestep.observation.action_mask.flatten(),\n",
        ")\n",
        "ems_id, item_id = jnp.divmod(ems_item_id, num_items)\n",
        "\n",
        "#Wrap the action as a jax array of shape (2,)\n",
        "action = jnp.array([ems_id, item_id])\n",
        "state, timestep = env.step(state, action)\n",
        "print(timestep.reward)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import chex\n",
        "import jax.numpy as jnp"
      ],
      "metadata": {
        "id": "QJZD-48Dp-hf"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "7-JpZNsph_nH"
      },
      "outputs": [],
      "source": [
        "def flatten(obs):\n",
        "  p=[]  # obs = timestep.observation \n",
        "  p = np.append(obs.ems.x1,timestep.observation.ems.x2)\n",
        "  p = np.append(p,obs.ems.x2)\n",
        "  p = np.append(p,obs.ems.y1)\n",
        "  p = np.append(p,obs.ems.y2)\n",
        "  p = np.append(p,obs.ems.z1)\n",
        "  p = np.append(p,obs.ems.z2)\n",
        "  p = np.append(p,obs.ems_mask.flatten())\n",
        "  p = np.append(p,obs.items.x_len)\n",
        "  p = np.append(p,obs.items.y_len)\n",
        "  p = np.append(p,obs.items.z_len)\n",
        "  p = np.append(p,obs.items_mask.flatten())\n",
        "  p = np.append(p,obs.items_placed.flatten())\n",
        "  return p "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "p = flatten(timestep.observation)"
      ],
      "metadata": {
        "id": "jSHOCZ2nsK-S"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "p.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "WE29o1XaxDDw",
        "outputId": "f18664fb-7d6e-4467-e93b-df5815e4ede4"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(420,)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A_8XaiCMh_sB",
        "outputId": "7378e0c9-df01-4f2c-f978-b93fdade7734"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "jumanji.environments.combinatorial.binpack.types.Observation"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "type(timestep.observation)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rDAD_BVGi2P0"
      },
      "outputs": [],
      "source": [
        "timestep.observation.action_mask.flatten().shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fxleMe73i9Eq"
      },
      "outputs": [],
      "source": [
        "env.action_spec()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CiLncq7Ji9Hj"
      },
      "outputs": [],
      "source": [
        "env.observation_spec()"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Lu9eoPWAxU7n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model1 = FeedForwardNN(p.shape[0],800)\n",
        "p1 = model1.forward(np.array(p))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "xYwxRXLbxAWG",
        "outputId": "b4f83169-9e4d-45f2-a2bb-96d81fd9cf51"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "inside tensor\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "p1.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "R4ZByF_7PnqX",
        "outputId": "cc40882c-316a-4ab5-bea1-60ab057114c9"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([800])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "action_mask = pd.DataFrame(timestep.observation.action_mask.flatten())"
      ],
      "metadata": {
        "id": "pZ_RhOCTQA-x"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "ind = action_mask.index[[action_mask[0] == True]]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "V7erGynMqvzu",
        "outputId": "bc6962b3-c1f4-40bf-f69a-196b9efbb102"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pandas/core/indexes/base.py:4616: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
            "  result = getitem(key)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ind"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "3U4jjcyds5f5",
        "outputId": "c4a64b62-80c2-4a7b-faf3-5d6e74aa3253"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Int64Index([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 12, 13, 14, 15, 16, 17,\n",
              "            18, 19, 22, 23, 24, 26, 28, 29, 30, 32, 34, 35, 36, 37, 38, 39, 40,\n",
              "            41, 42, 44, 45, 47, 48, 50, 52, 53, 54, 57, 58],\n",
              "           dtype='int64')"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame(p1.detach().numpy())\n"
      ],
      "metadata": {
        "id": "CVuyauujrpeM"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.iloc[ind][0][4].index"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "OsLHcQX5wiSE",
        "outputId": "f32fa0ae-5d7a-4777-af82-3beb38c2ba4e"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0     0.001197\n",
              "1     0.001197\n",
              "2     0.001359\n",
              "3     0.001197\n",
              "4     0.001197\n",
              "5     0.001327\n",
              "6     0.001430\n",
              "7     0.001197\n",
              "8     0.001312\n",
              "9     0.001224\n",
              "10    0.001202\n",
              "12    0.001197\n",
              "13    0.001219\n",
              "14    0.001321\n",
              "15    0.001230\n",
              "16    0.001197\n",
              "17    0.001197\n",
              "18    0.001197\n",
              "19    0.001197\n",
              "22    0.001409\n",
              "23    0.001368\n",
              "24    0.001197\n",
              "26    0.001357\n",
              "28    0.001311\n",
              "29    0.001197\n",
              "30    0.001197\n",
              "32    0.001197\n",
              "34    0.001197\n",
              "35    0.001432\n",
              "36    0.001197\n",
              "37    0.001197\n",
              "38    0.001219\n",
              "39    0.001229\n",
              "40    0.001197\n",
              "41    0.001293\n",
              "42    0.001197\n",
              "44    0.001213\n",
              "45    0.001197\n",
              "47    0.001203\n",
              "48    0.001197\n",
              "50    0.001197\n",
              "52    0.001197\n",
              "53    0.001197\n",
              "54    0.001197\n",
              "57    0.001197\n",
              "58    0.001350\n",
              "Name: 0, dtype: float32"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "list(df.iloc[ind][0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "wNk4QWNpwK0e",
        "outputId": "fe2d9e47-c9db-4c5e-fe8d-09ddef8b81bc"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.001196884666569531,\n",
              " 0.001196884666569531,\n",
              " 0.0013587928842753172,\n",
              " 0.001196884666569531,\n",
              " 0.001196884666569531,\n",
              " 0.0013267110334709287,\n",
              " 0.0014303360367193818,\n",
              " 0.001196884666569531,\n",
              " 0.0013121668016538024,\n",
              " 0.0012236549519002438,\n",
              " 0.0012018720153719187,\n",
              " 0.001196884666569531,\n",
              " 0.0012193493312224746,\n",
              " 0.00132115522865206,\n",
              " 0.0012302374234423041,\n",
              " 0.001196884666569531,\n",
              " 0.001196884666569531,\n",
              " 0.001196884666569531,\n",
              " 0.001196884666569531,\n",
              " 0.0014090521726757288,\n",
              " 0.0013678219402208924,\n",
              " 0.001196884666569531,\n",
              " 0.0013568168506026268,\n",
              " 0.0013109107967466116,\n",
              " 0.001196884666569531,\n",
              " 0.001196884666569531,\n",
              " 0.001196884666569531,\n",
              " 0.001196884666569531,\n",
              " 0.0014315623557195067,\n",
              " 0.001196884666569531,\n",
              " 0.001196884666569531,\n",
              " 0.0012186352396383882,\n",
              " 0.0012291870079934597,\n",
              " 0.001196884666569531,\n",
              " 0.0012926310300827026,\n",
              " 0.001196884666569531,\n",
              " 0.00121268630027771,\n",
              " 0.001196884666569531,\n",
              " 0.0012028596829622984,\n",
              " 0.001196884666569531,\n",
              " 0.001196884666569531,\n",
              " 0.001196884666569531,\n",
              " 0.001196884666569531,\n",
              " 0.001196884666569531,\n",
              " 0.001196884666569531,\n",
              " 0.0013501702342182398]"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "action_mask = pd.DataFrame(timestep.observation.action_mask.flatten())\n",
        "ind = action_mask.index[[action_mask[0] == True]]\n",
        "df = pd.DataFrame(p1.detach().numpy())\n",
        "\n",
        "from torch.distributions import Categorical\n",
        "m = Categorical(probs = torch.tensor(list(df.iloc[ind][0])))\n",
        "a = m.sample() "
      ],
      "metadata": {
        "id": "eedoJW9mrrsr"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "ir7H3R1SuSmL",
        "outputId": "0c403d3f-82b5-47b4-f760-1e80aaa6fc36"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(3)"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "m.log_prob(a)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "Np462DABtavc",
        "outputId": "93ee5fc0-749b-4468-b3d9-ba7c3063b392"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(-3.8655)"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(timestep.observation.action_mask.flatten())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "vjcWvU5KUPbZ",
        "outputId": "6089b667-4c5f-413e-8f3c-764cd2a97e4e"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "jaxlib.xla_extension.DeviceArray"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame(p1.detach().numpy())\n",
        "df.iloc[list(timestep.observation.action_mask.flatten()),:]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1491
        },
        "id": "-1SGz49yPief",
        "outputId": "596e6a6e-e00f-45ee-b029-9a117cdafc43"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           0\n",
              "0   0.001198\n",
              "1   0.001227\n",
              "2   0.001198\n",
              "3   0.001350\n",
              "4   0.001198\n",
              "5   0.001305\n",
              "6   0.001198\n",
              "7   0.001198\n",
              "8   0.001198\n",
              "9   0.001198\n",
              "10  0.001198\n",
              "12  0.001280\n",
              "13  0.001377\n",
              "14  0.001298\n",
              "15  0.001198\n",
              "16  0.001284\n",
              "17  0.001376\n",
              "18  0.001198\n",
              "19  0.001240\n",
              "22  0.001198\n",
              "23  0.001270\n",
              "24  0.001245\n",
              "26  0.001198\n",
              "28  0.001198\n",
              "29  0.001198\n",
              "30  0.001201\n",
              "32  0.001198\n",
              "34  0.001245\n",
              "35  0.001198\n",
              "36  0.001198\n",
              "37  0.001198\n",
              "38  0.001315\n",
              "39  0.001429\n",
              "40  0.001198\n",
              "41  0.001228\n",
              "42  0.001198\n",
              "44  0.001198\n",
              "45  0.001212\n",
              "47  0.001198\n",
              "48  0.001227\n",
              "50  0.001212\n",
              "52  0.001291\n",
              "53  0.001198\n",
              "54  0.001198\n",
              "57  0.001264\n",
              "58  0.001198"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8ee07414-a264-413b-93d5-fc68e151588f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.001198</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.001227</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.001198</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.001350</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.001198</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.001305</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.001198</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.001198</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0.001198</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0.001198</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>0.001198</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>0.001280</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>0.001377</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>0.001298</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>0.001198</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>0.001284</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>0.001376</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>0.001198</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>0.001240</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>0.001198</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>0.001270</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>0.001245</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>0.001198</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>0.001198</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>0.001198</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>0.001201</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>0.001198</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>0.001245</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>0.001198</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>0.001198</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>0.001198</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>0.001315</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>0.001429</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>0.001198</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>0.001228</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>0.001198</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>0.001198</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45</th>\n",
              "      <td>0.001212</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47</th>\n",
              "      <td>0.001198</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48</th>\n",
              "      <td>0.001227</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50</th>\n",
              "      <td>0.001212</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>52</th>\n",
              "      <td>0.001291</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>53</th>\n",
              "      <td>0.001198</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>54</th>\n",
              "      <td>0.001198</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>57</th>\n",
              "      <td>0.001264</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>58</th>\n",
              "      <td>0.001198</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8ee07414-a264-413b-93d5-fc68e151588f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-8ee07414-a264-413b-93d5-fc68e151588f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-8ee07414-a264-413b-93d5-fc68e151588f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pd.DataFrame(timestep.observation.action_mask.flatten())"
      ],
      "metadata": {
        "id": "veXaUzSJXHck"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "id": "AbMh0J8b1wj_"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame(p1.detach().numpy())\n",
        "df.iloc[list(timestep.observation.action_mask.flatten()),:].idxmax()[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "zxLBPrKq1oNF",
        "outputId": "48e3317a-d139-4a19-e35d-8fdf658cb8a4"
      },
      "execution_count": 140,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9"
            ]
          },
          "metadata": {},
          "execution_count": 140
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "timestep.observation.action_mask.flatten()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "vNHXBJgY114G",
        "outputId": "c0f0863e-4294-4532-812a-3e172aaf8d45"
      },
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DeviceArray([ True,  True,  True,  True,  True,  True,  True,  True,\n",
              "              True,  True,  True, False,  True,  True,  True,  True,\n",
              "              True,  True,  True,  True, False, False,  True,  True,\n",
              "              True, False,  True, False,  True,  True,  True, False,\n",
              "              True, False,  True,  True,  True,  True,  True,  True,\n",
              "              True,  True,  True, False,  True,  True, False,  True,\n",
              "              True, False,  True, False,  True,  True,  True, False,\n",
              "             False,  True,  True, False, False, False, False, False,\n",
              "             False, False, False, False, False, False, False, False,\n",
              "             False, False, False, False, False, False, False, False,\n",
              "             False, False, False, False, False, False, False, False,\n",
              "             False, False, False, False, False, False, False, False,\n",
              "             False, False, False, False, False, False, False, False,\n",
              "             False, False, False, False, False, False, False, False,\n",
              "             False, False, False, False, False, False, False, False,\n",
              "             False, False, False, False, False, False, False, False,\n",
              "             False, False, False, False, False, False, False, False,\n",
              "             False, False, False, False, False, False, False, False,\n",
              "             False, False, False, False, False, False, False, False,\n",
              "             False, False, False, False, False, False, False, False,\n",
              "             False, False, False, False, False, False, False, False,\n",
              "             False, False, False, False, False, False, False, False,\n",
              "             False, False, False, False, False, False, False, False,\n",
              "             False, False, False, False, False, False, False, False,\n",
              "             False, False, False, False, False, False, False, False,\n",
              "             False, False, False, False, False, False, False, False,\n",
              "             False, False, False, False, False, False, False, False,\n",
              "             False, False, False, False, False, False, False, False,\n",
              "             False, False, False, False, False, False, False, False,\n",
              "             False, False, False, False, False, False, False, False,\n",
              "             False, False, False, False, False, False, False, False,\n",
              "             False, False, False, False, False, False, False, False,\n",
              "             False, False, False, False, False, False, False, False,\n",
              "             False, False, False, False, False, False, False, False,\n",
              "             False, False, False, False, False, False, False, False,\n",
              "             False, False, False, False, False, False, False, False,\n",
              "             False, False, False, False, False, False, False, False,\n",
              "             False, False, False, False, False, False, False, False,\n",
              "             False, False, False, False, False, False, False, False,\n",
              "             False, False, False, False, False, False, False, False,\n",
              "             False, False, False, False, False, False, False, False,\n",
              "             False, False, False, False, False, False, False, False,\n",
              "             False, False, False, False, False, False, False, False,\n",
              "             False, False, False, False, False, False, False, False,\n",
              "             False, False, False, False, False, False, False, False,\n",
              "             False, False, False, False, False, False, False, False,\n",
              "             False, False, False, False, False, False, False, False,\n",
              "             False, False, False, False, False, False, False, False,\n",
              "             False, False, False, False, False, False, False, False,\n",
              "             False, False, False, False, False, False, False, False,\n",
              "             False, False, False, False, False, False, False, False,\n",
              "             False, False, False, False, False, False, False, False,\n",
              "             False, False, False, False, False, False, False, False,\n",
              "             False, False, False, False, False, False, False, False,\n",
              "             False, False, False, False, False, False, False, False,\n",
              "             False, False, False, False, False, False, False, False,\n",
              "             False, False, False, False, False, False, False, False,\n",
              "             False, False, False, False, False, False, False, False,\n",
              "             False, False, False, False, False, False, False, False,\n",
              "             False, False, False, False, False, False, False, False,\n",
              "             False, False, False, False, False, False, False, False,\n",
              "             False, False, False, False, False, False, False, False,\n",
              "             False, False, False, False, False, False, False, False,\n",
              "             False, False, False, False, False, False, False, False,\n",
              "             False, False, False, False, False, False, False, False,\n",
              "             False, False, False, False, False, False, False, False,\n",
              "             False, False, False, False, False, False, False, False,\n",
              "             False, False, False, False, False, False, False, False,\n",
              "             False, False, False, False, False, False, False, False,\n",
              "             False, False, False, False, False, False, False, False,\n",
              "             False, False, False, False, False, False, False, False,\n",
              "             False, False, False, False, False, False, False, False,\n",
              "             False, False, False, False, False, False, False, False,\n",
              "             False, False, False, False, False, False, False, False,\n",
              "             False, False, False, False, False, False, False, False,\n",
              "             False, False, False, False, False, False, False, False,\n",
              "             False, False, False, False, False, False, False, False,\n",
              "             False, False, False, False, False, False, False, False,\n",
              "             False, False, False, False, False, False, False, False,\n",
              "             False, False, False, False, False, False, False, False,\n",
              "             False, False, False, False, False, False, False, False,\n",
              "             False, False, False, False, False, False, False, False,\n",
              "             False, False, False, False, False, False, False, False,\n",
              "             False, False, False, False, False, False, False, False,\n",
              "             False, False, False, False, False, False, False, False,\n",
              "             False, False, False, False, False, False, False, False,\n",
              "             False, False, False, False, False, False, False, False,\n",
              "             False, False, False, False, False, False, False, False,\n",
              "             False, False, False, False, False, False, False, False,\n",
              "             False, False, False, False, False, False, False, False,\n",
              "             False, False, False, False, False, False, False, False,\n",
              "             False, False, False, False, False, False, False, False,\n",
              "             False, False, False, False, False, False, False, False,\n",
              "             False, False, False, False, False, False, False, False,\n",
              "             False, False, False, False, False, False, False, False,\n",
              "             False, False, False, False, False, False, False, False,\n",
              "             False, False, False, False, False, False, False, False,\n",
              "             False, False, False, False, False, False, False, False,\n",
              "             False, False, False, False, False, False, False, False,\n",
              "             False, False, False, False, False, False, False, False],            dtype=bool)"
            ]
          },
          "metadata": {},
          "execution_count": 131
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "yQ3vZM0rjE8I"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "class FeedForwardNN(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(FeedForwardNN, self).__init__()\n",
        "  def __init__(self, in_dim, out_dim):\n",
        "    super(FeedForwardNN, self).__init__()\n",
        "    self.layer1 = nn.Linear(in_dim, 64)\n",
        "    self.layer2 = nn.Linear(64, out_dim)\n",
        "    self.layer3 = nn.Softmax()\n",
        "  def forward(self, obs):\n",
        "  # Convert observation to tensor if it's a numpy array\n",
        "    if isinstance(obs, np.ndarray):\n",
        "      obs = torch.tensor(obs, dtype=torch.float)\n",
        "      print(\"inside tensor\")\n",
        "  \n",
        "    activation1 = F.relu(self.layer1(obs))\n",
        "    activation2 = F.relu(self.layer2(activation1))\n",
        "    output = self.layer3(activation2)\n",
        "    return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1hZa7hu_jFAG"
      },
      "outputs": [],
      "source": [
        "model1 = FeedForwardNN(timestep.observation.action_mask.flatten().shape[0],800)\n",
        "p = model1.forward(np.array(timestep.observation.action_mask.flatten()))\n",
        "df = pd.DataFrame(p.detach().numpy())\n",
        "df.iloc[list(timestep.observation.action_mask.flatten()),:].idxmax()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 141,
      "metadata": {
        "id": "iMtNUWDyjxRb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "7003498c-253d-486d-a998-846731cd1a4b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DeviceArray(11, dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 141
        }
      ],
      "source": [
        "ems_item_id"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "action"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "FRgJN6816B4u",
        "outputId": "b8b50061-4426-4806-ed00-e6514169ea9c"
      },
      "execution_count": 149,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DeviceArray([ 0, 11], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 149
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "l = [ 0.25, 0.25, 0.25, 0.25 ]"
      ],
      "metadata": {
        "id": "J8frhkeQHJBR"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.distributions import MultivariateNormal,Categorical\n",
        "m = Categorical(torch.tensor(l))\n",
        "m.sample()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "5elpRWLVGp7E",
        "outputId": "6e818732-c1dc-48f8-eeaf-5b181a37eef4"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(3)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "l[3]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "BtQ9pR7cGy1S",
        "outputId": "67f9e4c1-b593-4adf-ac83-205fb6611a8b"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.25"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "id": "F8RSfua-G2us"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yCbmLLiYjqfB"
      },
      "source": [
        "## PPO"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "Xns65TLJjhYD"
      },
      "outputs": [],
      "source": [
        "from torch.distributions import MultivariateNormal,Categorical\n",
        "from torch.optim import Adam\n",
        "class PPO:\n",
        "  def __init__(self,env):\n",
        "    self._init_hyperparameters()\n",
        "    self.env = env\n",
        "    #####################################\n",
        "    self.obs_dim = 420\n",
        "    self.act_dim = 800\n",
        "    ######################################\n",
        "    \n",
        "\n",
        "    #initiate actor and critic\n",
        "    self.actor = FeedForwardNN(self.obs_dim,self.act_dim)\n",
        "    self.critic = FeedForwardNN(self.obs_dim,1)\n",
        "\n",
        "      # Create our variable for the matrix.\n",
        "    # Note that I chose 0.5 for stdev arbitrarily.\n",
        "    self.cov_var = torch.full(size=(self.act_dim,), fill_value=0.5)\n",
        "    \n",
        "    # Create the covariance matrix\n",
        "    self.cov_mat = torch.diag(self.cov_var)\n",
        "    self.actor_optim = Adam(self.actor.parameters(), lr=self.lr)\n",
        "    self.critic_optim = Adam(self.critic.parameters(), lr=self.lr)\n",
        "    \n",
        "    \n",
        "  def _init_hyperparameters(self):\n",
        "    # Default values for hyperparameters, will need to change later.\n",
        "    self.timesteps_per_batch = 4800            # timesteps per batch\n",
        "    self.max_timesteps_per_episode = 1600      # timesteps per episode\n",
        "    self.gamma = 0.95\n",
        "    self.n_updates_per_iteration = 5\n",
        "    self.clip = 0.2 # As recommended by the paper\n",
        "    self.lr = 0.005\n",
        "\n",
        "  def compute_rtgs(self, batch_rews): \n",
        "    # The rewards-to-go (rtg) per episode per batch to return.\n",
        "    # The shape will be (num timesteps per episode)\n",
        "    batch_rtgs = []\n",
        "    # Iterate through each episode backwards to maintain same order\n",
        "    # in batch_rtgs\n",
        "    for ep_rews in reversed(batch_rews):\n",
        "      discounted_reward = 0 # The discounted reward so far\n",
        "      for rew in reversed(ep_rews):\n",
        "        discounted_reward = rew + discounted_reward * self.gamma\n",
        "        batch_rtgs.insert(0, discounted_reward)\n",
        "    # Convert the rewards-to-go into a tensor\n",
        "    batch_rtgs = torch.tensor(batch_rtgs, dtype=torch.float)\n",
        "    return batch_rtgs\n",
        "\n",
        "  def get_action(self,obs,action_mask):\n",
        "     p1 = self.actor(obs)\n",
        "     \n",
        "     \n",
        "     ind = action_mask.index[[action_mask[0] == True]]\n",
        "     df = pd.DataFrame(p1.detach().numpy())\n",
        "     probs = Categorical(probs=torch.tensor(list(df.iloc[ind][0])))\n",
        "     action = probs.sample()\n",
        "     action_id = df.iloc[ind][0][action].index\n",
        "     return action_id, action, probs.log_prob(action)#, probs.entropy(), self.critic(obs) \n",
        "    # model1 = FeedForwardNN(obs.shape[0],800)\n",
        "    # p1 = model1.forward(np.array(obs))\n",
        "    # df = pd.DataFrame(p1.detach().numpy())\n",
        "    #df.iloc[list(timestep.observation.action_mask.flatten()),:].idxmax()[0]\n",
        "\n",
        "    #return df.iloc[list(timestep.observation.action_mask.flatten()),:].idxmax()[0]\n",
        "  def rollout(self):\n",
        "    # Batch data\n",
        "    batch_obs = []             # batch observations\n",
        "    batch_acts = []            # batch actions\n",
        "    batch_log_probs = []       # log probs of each action\n",
        "    batch_rews = []            # batch rewards\n",
        "    batch_rtgs = []            # batch rewards-to-go\n",
        "    batch_lens = []            # episodic lengths in batch\n",
        "    # Number of timesteps run so far this batch\n",
        "    t = 0 \n",
        "    while t < self.timesteps_per_batch:\n",
        "      # Rewards this episode\n",
        "      ep_rews = []\n",
        "      key = jax.random.PRNGKey(0)\n",
        "      ###############################\n",
        "      #jax.jit(env.reset)(key)\n",
        "      state, timestep = self.env.reset(key)\n",
        "      ###############################\n",
        "    \n",
        "      for ep_t in range(self.max_timesteps_per_episode):\n",
        "\n",
        "        # Increment timesteps ran this batch so far\n",
        "        t += 1\n",
        "        # Collect observation\n",
        "        ################################################\n",
        "        obs = flatten(timestep.observation)\n",
        "        obs = torch.tensor(obs, dtype=torch.float)\n",
        "        batch_obs.append(obs)\n",
        "        \n",
        "        num_ems, num_items = env.action_spec().num_values\n",
        "        action_mask = pd.DataFrame(timestep.observation.action_mask.flatten())\n",
        "        #----------------------------------------------- get from NN\n",
        "        #ems_item_id = self.get_action(obs,action_mask)\n",
        "        ems_item_id, action_,log_prob  = self.get_action(obs,action_mask)\n",
        "        # -------------------------------------------------\n",
        "        ems_id, item_id = jnp.divmod(ems_item_id, num_items)\n",
        "\n",
        "        # Wrap the action as a jax array of shape (2,)\n",
        "        action = jnp.array([ems_id, item_id])\n",
        "\n",
        "        #action = torch.tensor(action, dtype=torch.float)\n",
        "        #ems_item_id, action_,log_prob  = self.get_action(obs,action_mask)\n",
        "        #mean = self.actor(obs)\n",
        "        #dist = MultivariateNormal(mean, self.cov_mat)\n",
        "        #log_prob = dist.log_prob(action)\n",
        "\n",
        "        state,timestep = self.env.step(action)\n",
        "        rew = timestep.reward\n",
        "        ##################################################\n",
        "        # Collect reward, action, and log prob\n",
        "        ep_rews.append(rew)\n",
        "        \n",
        "        batch_acts.append(action_)\n",
        "        batch_log_probs(log_prob)\n",
        "      # Collect episodic length and rewards\n",
        "      batch_lens.append(ep_t + 1) # plus 1 because timestep starts at 0\n",
        "      batch_rews.append(ep_rews) \n",
        "      # Reshape data as tensors in the shape specified before returning\n",
        "    batch_obs = torch.tensor(batch_obs, dtype=torch.float)\n",
        "    batch_acts = torch.tensor(batch_acts, dtype=torch.float)\n",
        "    batch_log_probs = torch.tensor(batch_log_probs, dtype=torch.float)\n",
        "    # ALG STEP #4\n",
        "    batch_rtgs = self.compute_rtgs(batch_rews)\n",
        "    # Return the batch data\n",
        "    return batch_obs, batch_acts,batch_log_probs, batch_rtgs, batch_lens\n",
        "\n",
        "  def learn(self, total_timesteps):\n",
        "    t_so_far = 0 # Timesteps simulated so far\n",
        "    while t_so_far < total_timesteps:              # ALG STEP 2\n",
        "      # Increment t_so_far somewhere below\n",
        "      # ALG STEP 3\n",
        "      batch_obs, batch_acts,batch_log_probs, batch_rtgs, batch_lens = self.rollout()\n",
        "      # Calculate how many timesteps we collected this batch   \n",
        "      t_so_far += np.sum(batch_lens)\n",
        "      # Calculate V_{phi, k}\n",
        "      V, _ = self.evaluate(batch_obs, batch_acts)\n",
        "      # ALG STEP 5\n",
        "      # Calculate advantage\n",
        "      A_k = batch_rtgs - V.detach()\n",
        "      # Normalize advantages\n",
        "      A_k = (A_k - A_k.mean()) / (A_k.std() + 1e-10)\n",
        "      for _ in range(self.n_updates_per_iteration):\n",
        "        # Calculate V_phi and pi_theta(a_t | s_t)    \n",
        "        V, curr_log_probs = self.evaluate(batch_obs, batch_acts)\n",
        "        # Calculate ratios\n",
        "        ratios = torch.exp(curr_log_probs - batch_log_probs)\n",
        "        # Calculate surrogate losses\n",
        "        surr1 = ratios * A_k\n",
        "        surr2 = torch.clamp(ratios, 1 - self.clip, 1 + self.clip) * A_k\n",
        "        actor_loss = (-torch.min(surr1, surr2)).mean()\n",
        "        # Calculate gradients and perform backward propagation for actor \n",
        "        # network\n",
        "        self.actor_optim.zero_grad()\n",
        "        actor_loss.backward()\n",
        "        self.actor_optim.step()\n",
        "        critic_loss = nn.MSELoss()(V, batch_rtgs)\n",
        "        # Calculate gradients and perform backward propagation for critic network    \n",
        "        self.critic_optim.zero_grad()    \n",
        "        critic_loss.backward()    \n",
        "        self.critic_optim.step()\n",
        "    \n",
        "  def evaluate(self, batch_obs,batch_acts):\n",
        "    # Query critic network for a value V for each obs in batch_obs.\n",
        "    V = self.critic(batch_obs).squeeze()\n",
        "    # Calculate the log probabilities of batch actions using most \n",
        "    # recent actor network.\n",
        "    # This segment of code is similar to that in get_action()\n",
        "    mean = self.actor(batch_obs)\n",
        "    dist = Categorical(mean)\n",
        "    log_probs = dist.log_prob(batch_acts)\n",
        "    # Return predicted values V and log probs log_probs\n",
        "    return V, log_probs\n",
        " \n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "kmqsDt3BjtaN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 608
        },
        "outputId": "2c5b3ab6-6105-436f-d581-7e828a4ccf0d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/jax/_src/numpy/lax_numpy.py:173: UserWarning: Explicitly requested dtype float64 requested in asarray is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
            "  return asarray(x, dtype=self.dtype)\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "/usr/local/lib/python3.7/dist-packages/pandas/core/indexes/base.py:4616: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
            "  result = getitem(key)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3360\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3361\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3362\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/index_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.index.Int64Engine._check_type\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/index_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.index.Int64Engine._check_type\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: tensor(4)",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-538d8c81b35e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPPO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-9-09b238fd39de>\u001b[0m in \u001b[0;36mlearn\u001b[0;34m(self, total_timesteps)\u001b[0m\n\u001b[1;32m    136\u001b[0m       \u001b[0;31m# Increment t_so_far somewhere below\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m       \u001b[0;31m# ALG STEP 3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 138\u001b[0;31m       \u001b[0mbatch_obs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_acts\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_log_probs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_rtgs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_lens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrollout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    139\u001b[0m       \u001b[0;31m# Calculate how many timesteps we collected this batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m       \u001b[0mt_so_far\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_lens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-9-09b238fd39de>\u001b[0m in \u001b[0;36mrollout\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     98\u001b[0m         \u001b[0;31m#----------------------------------------------- get from NN\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0;31m#ems_item_id = self.get_action(obs,action_mask)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m         \u001b[0mems_item_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlog_prob\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_action\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maction_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m         \u001b[0;31m# -------------------------------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m         \u001b[0mems_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdivmod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mems_item_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_items\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-9-09b238fd39de>\u001b[0m in \u001b[0;36mget_action\u001b[0;34m(self, obs, action_mask)\u001b[0m\n\u001b[1;32m     57\u001b[0m      \u001b[0mprobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCategorical\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mind\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m      \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m      \u001b[0maction_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mind\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m      \u001b[0;32mreturn\u001b[0m \u001b[0maction_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_prob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#, probs.entropy(), self.critic(obs)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;31m# model1 = FeedForwardNN(obs.shape[0],800)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    940\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    941\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mkey_is_scalar\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 942\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    943\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    944\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_hashable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m_get_value\u001b[0;34m(self, label, takeable)\u001b[0m\n\u001b[1;32m   1049\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1050\u001b[0m         \u001b[0;31m# Similar to Index.get_value, but we do not fall back to positional\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1051\u001b[0;31m         \u001b[0mloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_values_for_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3361\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3362\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3363\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3365\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhasnans\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: tensor(4)"
          ]
        }
      ],
      "source": [
        "model = PPO(env)\n",
        "model.learn(10)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if isinstance(action, np.ndarray):\n",
        "  action = torch.tensor(action, dtype=torch.float)\n",
        "  print(\"inside action tensor\")\n",
        "else:\n",
        "  print(\"no\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "Tx-5h_fG_v2i",
        "outputId": "5dcbe4bb-f524-427f-8098-8e2e4f19679b"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "no\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 165
        },
        "id": "KtT_Hk3QJ2q6",
        "outputId": "f67eba36-86a5-40af-c6e3-8a98f52155df"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-3c6bdfe70d69>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mobs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'obs' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "action = torch.tensor(action)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 165
        },
        "id": "QA7aC7TWHB5X",
        "outputId": "ea16a7f0-da24-4f83-f6b4-d2b68723fc40"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-d797a2ffe903>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m: the read only flag is not supported, should always be False"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "b1Q_rBApHuFF",
        "outputId": "e8094003-3849-4c7e-c050-2f11c2528064"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.7/dist-packages (2.9.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied: flatbuffers<2,>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.12)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (14.0.6)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: tensorboard<2.10,>=2.9 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.9.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.27.0)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.19.6)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: keras<2.10.0,>=2.9.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.9.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tensorflow) (57.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from tensorflow) (21.3)\n",
            "Requirement already satisfied: tensorflow-estimator<2.10.0,>=2.9.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.9.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (4.1.1)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.4.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.1.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.3.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.2)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.21.6)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.50.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow) (0.38.4)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow) (1.5.2)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow) (2.14.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow) (2.23.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow) (0.4.6)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow) (1.0.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow) (0.6.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow) (1.8.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow) (3.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (4.9)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (5.2.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow) (4.13.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow) (3.10.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (0.4.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (2022.9.24)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (1.24.3)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow) (3.2.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->tensorflow) (3.0.9)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "action = tf.convert_to_tensor(action, dtype=tf.float32)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 328
        },
        "id": "EpLoQSg1HR1J",
        "outputId": "1545970b-4b1b-4d48-c965-257c0ee71751"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-b9f04aad1ed4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001b[0m\n\u001b[1;32m   1603\u001b[0m               \u001b[0;34mf\"Tensor conversion requested dtype {dtype.name} \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1604\u001b[0m               \u001b[0;34mf\"for Tensor with dtype {value.dtype.name}: {value!r}\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1605\u001b[0;31m               name=name))\n\u001b[0m\u001b[1;32m   1606\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1607\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Tensor conversion requested dtype int32 for Tensor with dtype float32: <tf.Tensor: shape=(2,), dtype=float32, numpy=array([ 0., 11.], dtype=float32)>"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "slk-5v50HYbk"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO2R9YGSRADX75JmomA0B4U",
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}